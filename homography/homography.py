# -*- coding: utf-8 -*-
"""Court_Corners_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14K_Rcqpw67MSC9x1zzBBTW6JFTzektEN
"""

# !pip uninstall opencv-python -y
# !pip uninstall opencv-contrib-python -y
# !pip install opencv-contrib-python

"""# **Functions to read and convert image to gray scale**"""

import cv2
from matplotlib import pyplot as plt
from sklearn.cluster import KMeans
import numpy as np
import math
from google.colab.patches import cv2_imshow

#cv2.ximgproc.thinning()

def read_image(path,show):
  image = cv2.imread(path)
  h, w,_ = image.shape
  if h < 720 or w < 1280:
    image =  cv2.resize(image, (1280, 720), interpolation=cv2.INTER_CUBIC)
  if h > 720 or w > 1280:
    image = cv2.resize(image, (1280, 720), interpolation=cv2.INTER_AREA)
  if show:
    display("Original image is: ",image)
  return image

def convert_to_gray_scale(image,show):
  img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
  if show:
    display("Gray scale image is: ",img_gray)
  return img_gray

def display(title,image):
  print(title)
  cv2_imshow(image)

"""# **Function for Image Binarization**"""

def image_binarization(image,show,thresh):
  ret,th1 = cv2.threshold(image,190,255,cv2.THRESH_BINARY)
  ret,th2 = cv2.threshold(image,190,255,cv2.THRESH_BINARY_INV)
  th3 = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)

  blur = cv2.GaussianBlur(image,(5,5),0)
  ret,th4 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
  ret,th5 = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)

  images = [th1,th2,th3,th4,th5]
  titles = ['BINARY','BINARY_INV','ADAPTIVE_MEAN','GAUSSIAN_OTSU','OTSU']
  thresh_dict = {'BINARY':th1,'BINARY_INV':th2,'ADAPTIVE_MEAN':th3,'GAUSSIAN_OTSU':th4,'OTSU':th5}
  if show:
    plt.figure(figsize=(12,8))
    for i in range(5):
      plt.subplot(3,2,i+1)
      plt.imshow(images[i],'gray')
      plt.title(titles[i])
      plt.xticks([])
      plt.yticks([])
    plt.subplot(3,2,6)
    plt.imshow(image,'gray')
    plt.title('ORIGINAL_IMAGE')
    plt.show()
  return thresh_dict[thresh]

"""# **Canny Edge Detection**
We use Canny Edge Detection to find the edges in the image (https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html)
"""

def canny_edge_detection(image,show):
  v = np.median(image)
  sigma = 0.33
  lower = int(max(0,(1.0-sigma)*v))
  upper = int(min(255,(1.0+sigma)*v))
  edges = cv2.Canny(image,lower,upper,apertureSize=3)
  if show:
    plt.figure(figsize=(12,8))
    plt.subplot(1,2,1)
    plt.imshow(image,cmap='gray')
    plt.title('ORIGINAL_IMAGE')
    plt.xticks([])
    plt.yticks([])
    plt.subplot(1,2,2)
    plt.imshow(edges,cmap='gray')
    plt.title('CANNY_EDGE_DETECTION')
    plt.xticks([])
    plt.yticks([])
    plt.show()
  return edges

"""# **HoughLines**
We apply Hough Transform. Info about it: (https://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm)
"""

def hough_line_transform(image,show):
  cdstp = cv2.cvtColor(image,cv2.COLOR_GRAY2BGR)
  lines = cv2.HoughLinesP(image,1,np.pi/90,90,None,10,250)

  if lines is not None:
    for line in lines:
      x1,y1,x2,y2 = line[0]
      cv2.line(cdstp,(x1,y1),(x2,y2),(0,255,0),2,cv2.LINE_AA)
  if show:
    #display("Detected Lines (in Green) - Probabilistic Line Transform", cdstp)
    plt.figure(figsize=(8,6))
    plt.imshow(cdstp, cmap='magma')
    plt.title('All Hough Lines'), plt.xticks([]), plt.yticks([])
    plt.show()
  return lines

"""# **Extracting Horizontal and Vertical Lines**
The idea is that horizontal lines will have roughly equal y-coordinates, while vertical will have similar x coordinates. However, because of the camera angles, the vertical lines of the court come out diagonal which is why the deltaX value in the code cell below has been set to 280 (Obtained through trial and error)
"""

def segment_lines(lines, deltaX, deltaY):
    h_lines = []
    v_lines = []
    for line in lines:
        for x1, y1, x2, y2 in line:
            if abs(y2-y1) < deltaY: # y-values are near; line is horizontal
                h_lines.append(line)
            elif abs(x2-x1) < deltaX: # x-values are near; line is vertical
                v_lines.append(line)
    print('Total number of lines: ', lines.shape[0])
    print('Number of horizontal lines: ', len(h_lines))
    print('Number of vertical lines: ', len(v_lines))
    return h_lines, v_lines

def show_lines(image, lines, line_title):
    cpy_image = image.copy()
    for line in lines:
        x1, y1, x2, y2 = line[0]
        cv2.line(cpy_image, (x1, y1), (x2, y2), (0, 255, 0), 2,cv2.LINE_AA)
    plt.figure(figsize=(8,6))
    plt.imshow(cpy_image, cmap='magma')
    plt.title(line_title), plt.xticks([]), plt.yticks([])
    plt.show()

"""# **Getting Court Boundaries**"""

def filterLines(segments,minLength, maxLength):
  result = []
  for segment in segments:
    for x1,y1,x2,y2 in segment:
      if minLength < math.dist([x1,y1] , [x2,y2]) < maxLength:
        # For Brute Testing
        print(x1,y1, '\t', x2,y2, '\t', math.dist([x1,y1] , [x2,y2]))
        result.append(segment)
  print('----------------------------')
  return result

def getCourtLines(hsegments,vsegments):
  h_result = []
  v_result = []

  for segment in hsegments:
    for x1,y1,x2,y2 in segment:
      if (447.0 < math.dist([x1,y1] , [x2,y2]) < 449.0) or  (883.0 < math.dist([x1,y1] , [x2,y2]) < 885.0):
        h_result.append(segment)
  for segment in vsegments:
    for x1,y1,x2,y2 in segment:
      if (447.0 < math.dist([x1,y1] , [x2,y2])):
        v_result.append(segment)
  print('Filtered Vertical Lines: ', len(v_result))
  print('Filtered Horizontal Lines: ', len(h_result))
  return h_result, v_result

def showCourtLines(image,h_lines,v_lines):
  cpy_image = image.copy()

  for line in h_lines:
    x1, y1, x2, y2 = line[0]
    cv2.line(cpy_image, (x1, y1), (x2, y2), (0, 255, 0), 2,cv2.LINE_AA)

  for line in v_lines:
    x1, y1, x2, y2 = line[0]
    cv2.line(cpy_image, (x1, y1), (x2, y2), (0, 255, 0), 2,cv2.LINE_AA)

  plt.figure(figsize=(12,8))
  plt.imshow(cpy_image, cmap='magma')
  plt.title('Court Boundaries'), plt.xticks([]), plt.yticks([])
  plt.show()

def horizontal_projection(thinned_image):
    return np.sum(thinned_image > 0, axis=1)

def vertical_projection(thinned_image):
    ar = np.sum(thinned_image > 0, axis=0)
    ar[:50] = 0
    ar[1230:]=0
    return ar

def suppress_noise(proj):
    mean_val = math.floor(proj.mean())
    proj2 = proj - mean_val
    proj2[proj2 < 0] = 0
    return proj2.astype(np.int32)

def preprocess_thin(thinned):
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15,1))
    closed = cv2.morphologyEx(thinned, cv2.MORPH_CLOSE, kernel)

    dil_k = cv2.getStructuringElement(cv2.MORPH_RECT, (1,2))
    dilated = cv2.dilate(closed, dil_k, iterations=1)

    from skimage.morphology import skeletonize
    skeleton = skeletonize(dilated>0).astype(np.uint8)*255

    return skeleton

def show_horizontal_projection(image, proj):
    cpy_image = image.copy()
    H, W = cpy_image.shape
    hist = np.zeros((H, W), dtype=np.uint8)
    for i in range(H):
      hist[i, :proj[i]] = 255
    plt.figure(figsize=(16,16))
    plt.subplot(121), plt.imshow(image, cmap='gray')
    plt.title('Original Image'), plt.xticks([]), plt.yticks([])
    plt.subplot(122), plt.imshow(hist, cmap='gray')
    plt.title('Horizontal Projection Histogram'), plt.xticks([]), plt.yticks([])
    plt.subplots_adjust(wspace=0.01, hspace=0)
    plt.show()

def show_vertical_projection(image, proj):
    cpy_image = image.copy()
    H, W = cpy_image.shape
    hist = np.zeros((H, W), dtype=np.uint8)
    for i in range(W):
      hist[:proj[i], i] = 255
    plt.figure(figsize=(16,16))
    plt.subplot(221), plt.imshow(image, cmap='gray')
    plt.title('Original Image'), plt.xticks([]), plt.yticks([])
    plt.subplot(121), plt.imshow(hist, cmap='gray')
    plt.title('Vertical Projection Histogram'), plt.xticks([]), plt.yticks([])
    plt.subplots_adjust(wspace=0, hspace=0.1)
    plt.show()

def top_k_peaks(proj, k=6, min_distance=5):
    """
    Find the indices of the top-k peaks in the 1D array proj.
    Enforces a minimum distance between peaks to avoid picking
    multiple bins from the same wide spike.
    """
    proj = proj.ravel()
    candidates = []

    # make a copy so we can zero out neighborhoods
    temp = proj.copy().astype(float)

    for _ in range(k):
        idx = np.argmax(temp)
        val = temp[idx]
        if val <= 0:
            break
        candidates.append(idx)

        # zero out a window around this peak to enforce min_distance
        lo = max(0, idx - min_distance)
        hi = min(len(temp), idx + min_distance + 1)
        temp[lo:hi] = 0

    return sorted(candidates)

class ProjectionLearner:
    def __init__(self, n_peaks=6):
        self.n_peaks = n_peaks
        self.trained = False

    def offline_train(self, proj_list):
        """
        proj_list: list of 1D numpy arrays (horizontal projections after noise suppression)
        We will:
          - For each proj, find the indices of its top n_peaks bins.
          - Stack all these indices into a 2D array of shape (N * n_peaks, 1).
          - KMeans(n_clusters=2) on those indices to learn two typical row‐positions.
        """
        all_idxs = []
        for p in proj_list:
            # argsort gives ascending; take last n_peaks
            idxs = (top_k_peaks(p))[-self.n_peaks:]
            all_idxs.extend(idxs)
        data = np.array(all_idxs).reshape(-1,1)

        km = KMeans(n_clusters=2, random_state=0).fit(data)
        centers = sorted(km.cluster_centers_.flatten())
        self.centers_ = centers  # [Y_small, Y_large]
        self.trained = True

    def online_update(self, proj):
        """
        proj: single 1D projection (after noise suppression)
        Returns: (y1, y2) as the two learned row positions
        """
        assert self.trained, "Call offline_train first"
        # 1) find the six highest bins
        #idxs = np.argsort(proj)[-self.n_peaks:]
        idxs = top_k_peaks(proj, self.n_peaks)
        # 2) take the two largest indices as initial guesses
        y1_init, y2_init = idxs[-1], idxs[-2]
        print(y1_init, y2_init,idxs)

        # 3) refine each by searching ±5 rows to minimize distance to learned centers
        def refine(y_init, target_center):
            lo = max(0, y_init - 3)
            hi = min(len(proj)-1, y_init + 3)
            local_idxs = np.arange(lo, hi+1)
            # find row whose index is closest to target_center
            # (since centers are row‐positions)
            best = np.argmin(np.abs(local_idxs - target_center))
            return local_idxs[best]

        y1 = refine(y1_init, self.centers_[0])
        y2 = refine(y2_init, self.centers_[1])

        # 4) update centers by averaging in the new positions
        self.centers_[0] = (self.centers_[0] + y1) / 2
        self.centers_[1] = (self.centers_[1] + y2) / 2

        return int(y1), int(y2)

def harris_corner(image,gray,blockSize,ksize,k):
    '''
    Inputs:
      image: Base Image
      gray - grayscaled/thinned image/band of thinned image
      blockSize - window size for the Gaussian Smoothing (larger values will make corners less localized)
      ksize - kernel size for the sobel operators
      k - Harris detector free parameter (smaller values allow more features to be detected)
    Output:
      corners - array of corners
    '''
    # compute Harris Corner responses
    R = cv2.cornerHarris(gray, blockSize, ksize, k)

    # dilate
    R = cv2.dilate(R, None)

    # threshold image and convert to uint8
    ret, dst = cv2.threshold(R, 0.05*R.max(), 255, 0)
    dst = np.uint8(dst)

    # find centroids
    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)

    # define the criteria to stop and refine the corners
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)
    corners = cv2.cornerSubPix(gray, np.float32(centroids), (5,5), (-1,-1), criteria)

    # draw detected corners on the image
    if len(image.shape) > 2:
        image_out = image.copy()
    else:
        image_out = np.dstack((image, image, image))

    for (x, y) in corners:
        x = np.round(x).astype(int)
        y = np.round(y).astype(int)
        cv2.circle(image_out, (x, y), radius=3, color=(0, 255, 0), thickness=-1)
    plt.figure(figsize=(12,8))
    plt.subplot(1,2,1)
    plt.imshow(image,cmap='gray')
    plt.title('ORIGINAL_IMAGE')
    plt.xticks([])
    plt.yticks([])
    plt.subplot(1,2,2)
    plt.imshow(image_out,cmap='gray')
    plt.title('HARRIS_CORNER_DETECTION')
    plt.xticks([])
    plt.yticks([])
    plt.show()
    return corners

def detect_corners_on_lines(thinned, y_positions):
    """
    thinned: single‐pixel skeleton image (0/255)
    y_positions: list or tuple of two row indices [y1, y2]

    Returns: list of corner (x,y) coordinates
    """
    # prepare 4 structuring elements for hit‐or‐miss (square, diamond, cross, X)
    # based on Lopez‐Moreno morphological corner detector
    print(np.unique(thinned,return_counts=True))
    SEs = [
        np.array([[0,1,0],
                  [1,1,1],
                  [0,1,0]], dtype=np.uint8),  # diamond

        np.array([[1,0,1],
                  [0,1,0],
                  [1,0,1]], dtype=np.uint8),  # diamond

        np.array([[0,0,1],
                  [0,1,0],
                  [1,0,0]], dtype=np.uint8),  # L‐shape

        np.array([[1,0,0],
                  [0,1,0],
                  [0,0,1]], dtype=np.uint8),  # inverted L‐shape

        np.array([[0,0,0],
                  [1,1,1],
                  [0,1,0]], dtype=np.uint8),  # T‐shape

        np.array([[0,1,0],
                  [1,1,1],
                  [0,0,0]], dtype=np.uint8),  # inverted T‐shape

        np.array([[0,1,0],
                  [0,1,1],
                  [0,1,0]], dtype=np.uint8),  # Z‐shape

        np.array([[0,1,0],
                  [1,1,0],
                  [0,1,0]], dtype=np.uint8),  # inverted Z‐shape

        np.array([[0,1,0],
                  [0,1,1],
                  [0,0,0]], dtype=np.uint8),   # square

        np.array([[0,1,0],
                  [1,1,0],
                  [0,0,0]], dtype=np.uint8),   # cross

        np.array([[0,0,0],
                  [0,1,1],
                  [0,1,0]], dtype=np.uint8),   # X

        np.array([[0,0,0],
                  [1,1,0],
                  [0,1,0]], dtype=np.uint8),   # inverted X

        np.array([[0,0,1],
                  [1,1,0],
                  [0,0,0]], dtype=np.uint8),  # L‐shape

        np.array([[1,0,0],
                  [0,1,1],
                  [0,0,0]], dtype=np.uint8),  # inverted L‐shape

        np.array([[0,0,0],
                  [0,1,1],
                  [1,0,0]], dtype=np.uint8),  # L‐shape

        np.array([[0,0,0],
                  [1,1,0],
                  [0,0,1]], dtype=np.uint8),  # inverted L‐shape

        np.array([[1,0,0],
                  [0,1,0],
                  [0,1,0]], dtype=np.uint8),  # inverted L‐shape

        np.array([[0,1,0],
                  [0,1,0],
                  [1,0,0]], dtype=np.uint8),  # inverted L‐shape

        np.array([[0,1,0],
                  [0,1,0],
                  [0,0,1]], dtype=np.uint8),  # inverted L‐shape

        np.array([[0,0,1],
                  [0,1,0],
                  [0,1,0]], dtype=np.uint8),  # inverted L‐shape
    ]

    corners = []
    h, w = thinned.shape
    p = set()
    for y in y_positions:
        # extract a narrow band around the line
        band = np.zeros_like(thinned)
        band[max(0,y-2):min(h,y+3), :] = thinned[max(0,y-2):min(h,y+3), :]
        print("before for loop: ",np.unique(band,return_counts=True))
        # cascade hit‐or‐miss with each SE
        hit = band.copy()
        print("hit: ",hit.shape)
        # dst = harris_corner(hit,hit,2,3,0.04)
        # print("DST : ",dst)
        dst = harris_corner(thinned,band,12,3,0.05)
        print("DST with my: ",dst)
        #print("hit: ",hit[max(0,y-2):min(h,y+3), 600:700])
        for se in SEs:
            hit = cv2.morphologyEx(hit, cv2.MORPH_HITMISS, se)
            #print("at each se: ",np.unique(hit,return_counts=True),"\n",se)
            ys, xs = np.nonzero(hit)
            ps = set(zip(ys, xs))
            p = p.union(ps)
            #print('xs and ys are: ',xs,ys)
            #print("hit: ",hit[max(0,y-2):min(h,y+3), 600:700]," xs and ys: ", np.nonzero(hit))
            hit = band.copy()
            #print('hit is: ',hit,'for ',se)

        # find nonzero pixels = corner candidates
        #ys, xs = np.nonzero(hit)
        print(' Ps are: ',p)
        # we only want the four extreme corners: leftmost/rightmost on each of the two lines
        if len(xs)==0:
            continue
        # group by top/bottom half of the band to separate two corners per line
        midx = np.median(xs)
        left_x = xs[xs < midx]
        right_x = xs[xs >= midx]
        if len(left_x)>0:
            x0 = left_x.min()
            corners.append((x0, y))
        if len(right_x)>0:
            x1 = right_x.max()
            corners.append((x1, y))

    # If more than 4 found, pick the 4 extreme: minx/miny, minx/maxy, maxx/miny, maxx/maxy
    if len(corners) > 4:
        xs = [c[0] for c in corners]
        ys = [c[1] for c in corners]
        candidates = [
            (min(xs), min(ys)),
            (min(xs), max(ys)),
            (max(xs), min(ys)),
            (max(xs), max(ys))
        ]
        corners = candidates
    return corners

"""Output cell"""

ori_image = read_image('/content/drive/MyDrive/SMAI-PROJECT/court_data/Court_type (13).jpg',show=False)
#ori_image = read_image('/content/test1.jpg',True)
gray_image = convert_to_gray_scale(ori_image,show=False)

bin_image = image_binarization(gray_image,show=False,thresh='BINARY')

thinned_image = cv2.ximgproc.thinning(bin_image)

#display('Thinned image is: ',thinned_image)
thinned_image = preprocess_thin(thinned_image)
display('Thinned image is after median blurr: ',thinned_image)
thinned_bin = (thinned_image > 0).astype(np.uint8)

dst = harris_corner(thinned_image,thinned_image,12,3,0.05)

proj_before = horizontal_projection(thinned_bin)
proj_after  = suppress_noise(proj_before)

# print('Before suppressing Noise: ')
# show_horizontal_projection(thinned_image, proj_before)
# print('After suppressing Noise: ')
show_horizontal_projection(thinned_image, proj_after)

proj_vertical = vertical_projection(thinned_bin)
#show_vertical_projection(thinned_image, proj_vertical)
proj_vertical_after = suppress_noise(proj_vertical)
show_vertical_projection(thinned_image, proj_vertical_after)

#Train on projections data
proj_list = np.load('/content/projections.npy')
learner = ProjectionLearner()
learner.offline_train(proj_list)
np.save('learned_centers.npy',learner.centers_)

centers = np.load('learned_centers.npy')
learner = ProjectionLearner()
learner.centers_ = centers.tolist()
learner.trained = True
y1, y2 = learner.online_update(proj_after)
np.save('learned_centers.npy',learner.centers_)
corners = detect_corners_on_lines(thinned_image, [y1, y2])
print(y1,y2,corners)

y_peaks = top_k_peaks(proj_after, k=6, min_distance=5)
corners = detect_corners_on_lines(thinned_image, [y_peaks[3], y_peaks[2]])
print("Top 6 line rows:", y_peaks," my corners: ",corners," x: ",np.argmax(proj_vertical_after)," ",np.sum(proj_vertical_after[np.argmax(proj_vertical_after)]))
arr = np.array(thinned_bin)
print(np.sum(arr[y_peaks[5]]),np.sum(arr[y1]))

# cany_edge = canny_edge_detection(thinned_image,show=True)
# display('Canny edge is: ',cany_edge)
# print(np.array(bin_image))
# lines = hough_line_transform(cany_edge,show=True)
# h_lines, v_lines = segment_lines(lines, 280, 10)

# show_lines(ori_image, v_lines, 'Vertical Lines')
# show_lines(ori_image, h_lines, 'Horizontal Lines')


#filtered_h_lines, filtered_v_lines = getCourtLines(filterLines(h_lines,350,900),filterLines(v_lines,430,510))
#showCourtLines(ori_image,filterLines(h_lines,350,900),filterLines(v_lines,430,510))
#bin_image = apply_binary_thresholding(gray_image,show=False)
#cont_image = detect_and_draw_contours(bin_image,ori_image,False)



